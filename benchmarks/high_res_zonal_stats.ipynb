{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask_geopandas\n",
    "import rioxarray\n",
    "import geopandas as gpd\n",
    "import os\n",
    "from xrspatial.zonal import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raster(vpu_id, layer):\n",
    "    raster_path = f'high_res_data/NHDPLUS_H_{vpu_id}_HU4_RASTERS/HRNHDPlusRasters{vpu_id}/{layer}.tif'\n",
    "    if not os.path.exists(raster_path):\n",
    "        raise FileNotFoundError(f\"Raster file not found: {raster_path}\")\n",
    "    return rioxarray.open_rasterio(raster_path, chunks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vector_data(in_zone_data_path, vpu_id=None):\n",
    "    #TODO add layer parameter so we can do all layers in the dask_geopandas file\n",
    "    if vpu_id:\n",
    "        vpu_data_path = os.path.join(in_zone_data_path, f'NHDPLUS_H_{vpu_id}_HU4_GDB.gdb')\n",
    "        if not os.path.exists(vpu_data_path):\n",
    "            raise FileNotFoundError(f\"VPU geodatabase not found: {vpu_data_path}\")\n",
    "        return dask_geopandas.read_file(vpu_data_path, layer='NHDPlusCatchment')\n",
    "    else:\n",
    "        return dask_geopandas.read_file(in_zone_data_path, layer='NHDPlusCatchment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_zonal_stats(raster, vector_data):\n",
    "    # Ensure the vector data is reprojected to match the raster CRS\n",
    "    vector_data = vector_data.to_crs(raster.rio.crs)\n",
    "    \n",
    "    # Convert vector data to a rasterized form\n",
    "    zones = raster.rio.clip(vector_data.geometry, vector_data.crs, drop=False)\n",
    "    zones.values = vector_data['nhdplusid'].values\n",
    "    \n",
    "    # Compute zonal statistics\n",
    "    stats_df = stats(\n",
    "        zones=zones,\n",
    "        values=raster,\n",
    "        stats_funcs=['mean', 'median', 'min', 'max', 'count'],\n",
    "        return_type='pandas.DataFrame'\n",
    "    )\n",
    "    \n",
    "    return stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_vpu(vpu_id, layer, in_zone_data_path, output_path):\n",
    "    try:\n",
    "        # Load raster data\n",
    "        raster = load_raster(vpu_id, layer)\n",
    "        \n",
    "        # Load vector data\n",
    "        vector_data = load_vector_data(in_zone_data_path, vpu_id)\n",
    "        \n",
    "        # Compute zonal statistics\n",
    "        zonal_stats = compute_zonal_stats(raster, vector_data)\n",
    "        \n",
    "        # Save the results\n",
    "        output_file = os.path.join(output_path, f'zonal_stats_{vpu_id}.csv')\n",
    "        zonal_stats.to_csv(output_file)\n",
    "        \n",
    "        print(f\"Processed VPU {vpu_id} and saved results to {output_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing VPU {vpu_id}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(layer, in_zone_data_path, output_path, vpu_ids):\n",
    "    for vpu_id in vpu_ids:\n",
    "        process_vpu(vpu_id, layer, in_zone_data_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    layer = 'filldepth'\n",
    "    in_zone_data_path = 'high_res_data/NHDPlus_H_National_Release_1_GDB/NHDPlus_H_National_Release_1_GDB.gdb'\n",
    "    output_path = 'high_res_data/output'\n",
    "    vpu_ids = [1710, 1709]\n",
    "    \n",
    "    main(layer, in_zone_data_path, output_path, vpu_ids)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
